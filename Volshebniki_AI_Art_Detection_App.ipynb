{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "n7C5UtvkTb5E",
        "L0m-8VQfcyXG",
        "laLmuK43ghle"
      ],
      "mount_file_id": "1MSPyTO4gywxdpZP3cjDfaZOoTJh_jf7r",
      "authorship_tag": "ABX9TyOVN4CyEreK5+n/q+3Iuhqr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a3ulez/VAIAD/blob/main/Volshebniki_AI_Art_Detection_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üñå AI_Generated Art Detector üîç\n",
        "This notebook uses TensorFlow 2.18.0 and Tensor Hub to train a model to detect AI-generated artwork for companies testing the legitimacy of commissioned work.\n",
        "\n",
        "##Problem\n",
        "Wide availability of AI-powered models and online art has powered thieves to take others' work without permission to sell artwork generated by AI as their own work, endangering the financial stability of current artists as well as the future of unique human expression and online intercultural communication through art. Companies that want to support human artists need tools to help them recognize when AI-generated art has been marketed to or through them and help them make ethical business decisions.\n",
        "\n",
        "##Data\n",
        "The model was trained from this dataset available at Kaggle.com: https://www.kaggle.com/datasets/superpotato9/dalle-recognition-dataset/\n",
        "\n",
        "##Evaluation\n",
        "Target 75% accuracy of labeling art as human or AI-generated for this base layer application.\n",
        "Goal to specialize with proprietary art to 90% accuracy\n",
        "\n",
        "##Features\n",
        "Unstructured data :. best to learn deep learning / transfer learning\n",
        "No data file is provided for the image ids or classification and must be created\n",
        "Images in .jpg format in two classes:\n",
        "  Human-Generated - 3,781 (Reduced to 3,500)\n",
        "  AI-Generated - 17,857 (Reduced to 3,500)\n"
      ],
      "metadata": {
        "id": "bNe-ir2PuZpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Background Code"
      ],
      "metadata": {
        "id": "n7C5UtvkTb5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Main\n",
        "\"\"\"\n",
        "This application uses a TensorFlow model trained using the the EfficientNetV2\n",
        "feature extractor from TensorFlow Keras to recognize features of AI-generated\n",
        "art and make predictions about whether the image is AI-generated or not.\n",
        "\n",
        "Users can upload individual images or zip file of multiple images to run\n",
        "predictions and receive a csv file of the predictions and confidence levels\n",
        "and can display images with the predictions and confidence levels.\n",
        "\"\"\"\n",
        "\n",
        "#Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import kagglehub\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "#Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "9SNfHXMFFz1g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wrapper to use TF Hub model inside Keras model\n",
        "class HubFeatureExtractor(tfk.layers.Layer):\n",
        "    \"\"\"\n",
        "    Defines custom layer to use TF Hub feature vector module inside Keras model\n",
        "    \"\"\"\n",
        "    def __init__(self, hub_handle, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hub_layer = hub.load(hub_handle)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Assuming the hub module expects a single input.\n",
        "        # Adjust if the module has a different signature.\n",
        "        return self.hub_layer(inputs)\n"
      ],
      "metadata": {
        "id": "YSocTywQt0z1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Model"
      ],
      "metadata": {
        "id": "L0m-8VQfcyXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download model from GitHub\n",
        "!wget https://github.com/a3ulez/VAIAD/raw/40ee55d0139e58bc619c3c34780e7f9dfad78ee0/VAIAD_model.h5 -O model.h5\n",
        "\n",
        "# Then load the model\n",
        "loaded_model = tf.keras.models.load_model(\"model.h5\", custom_objects={\"KerasLayer\": hub.KerasLayer, \"HubFeatureExtractor\": HubFeatureExtractor})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNw0foQi1sPZ",
        "outputId": "c74e8743-9044-40ee-c693-c4bef930cfdc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 21:56:31--  https://github.com/a3ulez/VAIAD/raw/40ee55d0139e58bc619c3c34780e7f9dfad78ee0/VAIAD_model.h5\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/a3ulez/VAIAD/40ee55d0139e58bc619c3c34780e7f9dfad78ee0/VAIAD_model.h5 [following]\n",
            "--2025-07-13 21:56:31--  https://raw.githubusercontent.com/a3ulez/VAIAD/40ee55d0139e58bc619c3c34780e7f9dfad78ee0/VAIAD_model.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40512 (40K) [application/octet-stream]\n",
            "Saving to: ‚Äòmodel.h5‚Äô\n",
            "\n",
            "\rmodel.h5              0%[                    ]       0  --.-KB/s               \rmodel.h5            100%[===================>]  39.56K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-07-13 21:56:31 (10.6 MB/s) - ‚Äòmodel.h5‚Äô saved [40512/40512]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UI Background"
      ],
      "metadata": {
        "id": "laLmuK43ghle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_images_to_test():\n",
        "  \"\"\"\n",
        "  Invites user to upload image(s) to test if AI-generated\n",
        "  \"\"\"\n",
        "  print(\"Would you like to test one image or many?\")\n",
        "  print(\"1. One image\")\n",
        "  print(\"2. Many images (as a zip file)\")\n",
        "\n",
        "  image_paths = []\n",
        "\n",
        "  if input() == \"1\":\n",
        "    #Upload one image\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "      image_paths.append(fn)\n",
        "  else:\n",
        "    #Upload many images\n",
        "    print(\"Upload zip file of images\")\n",
        "    uploaded = files.upload()\n",
        "    image_paths = get_filename_list(uploaded)\n",
        "\n",
        "  #Confirm upload\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" to /contents'.format(name=fn))\n",
        "\n",
        "  return uploaded,image_paths"
      ],
      "metadata": {
        "id": "NnjQWYGYgwGL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to extract files from zip\n",
        "\n",
        "def get_filename_list(uploaded):\n",
        "    \"\"\"\n",
        "    Takes uploaded files and returns a list of file paths\n",
        "    \"\"\"\n",
        "    image_paths = []\n",
        "    for fn in uploaded.keys():\n",
        "        # Extract zip file in current directory\n",
        "        with zipfile.ZipFile(fn, \"r\") as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "            extracted_names = zip_ref.namelist()\n",
        "\n",
        "        # Iterate over all extracted files (full paths relative to cwd)\n",
        "        for name in extracted_names:\n",
        "            # Normalize path\n",
        "            filepath = os.path.normpath(name)\n",
        "\n",
        "            # Check if it's a file and has image extension\n",
        "            if os.path.isfile(filepath) and filepath.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                image_paths.append(filepath)\n",
        "\n",
        "    return image_paths"
      ],
      "metadata": {
        "id": "PGG2nPNNYF_k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Process Images into Tensors"
      ],
      "metadata": {
        "id": "zi6eZbKcoydV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get Filepath(s)"
      ],
      "metadata": {
        "id": "NGvINgi5q7VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function definition\n",
        "def process_img(img_path):\n",
        "  \"\"\"\n",
        "  Takes an image path and process the image into a 3-channel RGB tensor,\n",
        "  resizes it to a square of s = IMG_SIZE,\n",
        "  and returns the tensor\n",
        "  \"\"\"\n",
        "  try:\n",
        "    #Read in image file\n",
        "    image = tf.io.read_file(img_path)\n",
        "\n",
        "    #Decode image, allowing for different formats (JPEG, PNG, etc.)\n",
        "    image = tf.image.decode_image(image, channels=3)\n",
        "\n",
        "    # Ensure image has 3 channels (RGB) and is not None after decoding\n",
        "    if image is None or image.shape[-1] != 3:\n",
        "        print(f\"Skipping image with incorrect number of channels or invalid format: {img_path}\")\n",
        "        return None # Return None for invalid images\n",
        "\n",
        "    #Normalize color channel values\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    #Resize image\n",
        "    image = tf.image.resize(image, size=[IMG_SIZE,IMG_SIZE])\n",
        "\n",
        "    return image\n",
        "\n",
        "  except tf.errors.InvalidArgumentError as e:\n",
        "    print(f\"Skipping corrupted or invalid image: {img_path} - {e}\")\n",
        "    return None #Return None for corrupted or invalid images\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An unexpected error occurred while processing image {img_path}: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "qW0DQ98LnJn6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unbatch Uploaded Images"
      ],
      "metadata": {
        "id": "ERXfMg-AbPoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to unbatch uploaded images\n",
        "def unbatch_uploads(uploaded_data):\n",
        "  unbatched_images = []\n",
        "\n",
        "  for image in uploaded_data.unbatch().as_numpy_iterator():\n",
        "    unbatched_images.append(image)\n",
        "\n",
        "  return unbatched_images"
      ],
      "metadata": {
        "id": "D3c1vOllAVCp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Show Images Predicted as AI-Generated"
      ],
      "metadata": {
        "id": "DVvVhvvVBTY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to show images predicted as AI-generated\n",
        "def show_images_predicted_as_AI(predictions, image_paths, upload_data):\n",
        "    unbatched_images = unbatch_uploads(upload_data)\n",
        "\n",
        "    #Get image names\n",
        "    image_names = []\n",
        "    for image_path in image_paths:\n",
        "      image_names.append(image_path.split(\"/\")[-1])\n",
        "\n",
        "    #Remove Ticks\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    #Calculate confidence\n",
        "    confidence = [0] * len(predictions)\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "      confidence[i] = (1 - abs(predictions[i] - 0.5)) * 100\n",
        "\n",
        "    #Get predction label\n",
        "    predicted_label = [0] * len(predictions)\n",
        "    for i in range(len(predictions)):\n",
        "      if predictions[i] <= 0.5:\n",
        "        predicted_label[i] = \"AI\"\n",
        "      else:\n",
        "        predicted_label[i] = \"Human\"\n",
        "\n",
        "    #Show image for AI-generated predictions\n",
        "    for i in range(len(predictions)):\n",
        "      if predictions[i] <= 0.5:\n",
        "        plt.imshow(unbatched_images[i])\n",
        "        # Ensure image_names, predicted_label, and confidence are indexed correctly\n",
        "        plt.title(\"Image Name: {} | Predicted: {} | Confidence: {:.2f}%\".format(image_names[i], predicted_label[i], confidence[i].item())) # Use .item() to get the scalar value\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "0eRyFYEFBYO-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UI"
      ],
      "metadata": {
        "id": "TINiSUt5WEXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Main continued\n",
        "\n",
        "#UI Header\n",
        "print(\"Welcome to the Volshebniki, Inc. AI-Generated Art Detector\")\n",
        "print(\"\\n\\n\")\n",
        "run_test = input(\"Would you like to test an image? Y/N\\n\")\n",
        "\n",
        "while run_test.upper() == \"Y\": #Using .upper() to handle both 'y' and 'Y'\n",
        "  #Upload images to test\n",
        "  uploaded, image_paths = upload_images_to_test()\n",
        "\n",
        "  #Process uploaded images\n",
        "  processed_images = []\n",
        "  for image_path in image_paths:\n",
        "      processed_img = process_img(image_path)\n",
        "      if processed_img is not None:\n",
        "          processed_images.append(processed_img)\n",
        "\n",
        "  #Create batches of processed uploads\n",
        "  if processed_images:\n",
        "      processed_upload_data = tf.data.Dataset.from_tensor_slices(processed_images).batch(BATCH_SIZE)\n",
        "  else:\n",
        "      print(\"No valid images processed from the upload.\")\n",
        "      processed_upload_data = None\n",
        "\n",
        "\n",
        "  if processed_upload_data:\n",
        "      #Make predictions on test data using loaded full model\n",
        "      test_predictions = loaded_model.predict(processed_upload_data, verbose=1)\n",
        "\n",
        "      #Add columns to predictions with image name, label, and confidence\n",
        "      image_names = []\n",
        "      for image_path in image_paths:\n",
        "        image_names.append(image_path.split(\"/\")[-1])\n",
        "\n",
        "      prediction_rounded = [0] * len(test_predictions)\n",
        "      for i in range(len(test_predictions)):\n",
        "        if test_predictions[i] >= 0.5:\n",
        "          prediction_rounded[i] = 1\n",
        "        else:\n",
        "          prediction_rounded[i] = 0\n",
        "\n",
        "      #Find confidence of prediction\n",
        "      confidence = [0] * len(test_predictions)\n",
        "      for i in range(len(test_predictions)):\n",
        "        confidence[i] = (1 - abs(test_predictions[i] - 0.5)) * 100\n",
        "\n",
        "      #Corrected after video: Change prediction labels to be \"AI\" and \"Human\"\n",
        "      for i in range(len(prediction_rounded)):\n",
        "        if prediction_rounded[i] == 0:\n",
        "          prediction_rounded[i] = \"AI\"\n",
        "        else:\n",
        "          prediction_rounded[i] = \"Human\"\n",
        "\n",
        "      test_predictions_df = pd.DataFrame({\"Image Name\": image_names, \"Prediction\": prediction_rounded, \"Confidence\": confidence})\n",
        "\n",
        "      #Option: Save Predictions\n",
        "      print(\"Would you like to save the predictions? Y/N\\n\")\n",
        "      save_predictions = input()\n",
        "      if save_predictions.upper() == \"Y\":\n",
        "          #Save predictions dataframe to csv file with timestamp\n",
        "          timestamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "          #Create directory if it doesn't exist\n",
        "          path = \"/content/drive/MyDrive/AI_Art_Detector/predictions\"\n",
        "          os.makedirs(path, exist_ok=True)\n",
        "          suffix = \"test_predictions\"\n",
        "          filename = f\"{path}/{suffix}_{timestamp}.csv\"\n",
        "          test_predictions_df.to_csv(filename, index=False)\n",
        "          print(f\"Predictions saved to {filename}\")\n",
        "\n",
        "      #Option: Show Predictions\n",
        "      print(\"Would you like to see the predictions? Y/N\\n\")\n",
        "      show_predictions = input()\n",
        "      if show_predictions.upper() == \"Y\":\n",
        "          print(test_predictions_df)\n",
        "          print(\"\\n\\n\")\n",
        "\n",
        "          #Show bar graph with the number of those predicted to be AI-generated vs. human-generated\n",
        "          ai_count = (test_predictions_df[\"Prediction\"] == \"AI\").sum()\n",
        "          human_count = (test_predictions_df[\"Prediction\"] == \"Human\").sum()\n",
        "          labels = [\"AI\", \"Human\"]\n",
        "          counts = [ai_count, human_count]\n",
        "          plt.bar(labels, counts)\n",
        "          plt.xlabel(\"Prediction\")\n",
        "          plt.ylabel(\"Count\")\n",
        "          plt.title(\"Number of Predictions by Class\")\n",
        "          plt.tight_layout() #Corrected after video: making sure the tick marks show\n",
        "          plt.show()\n",
        "          print(\"\\n\\n\")\n",
        "\n",
        "      #Option: Show images predicted to be AI-generated\n",
        "      print(\"Would you like to see images predicted to be AI-generated? Y/N\\n\")\n",
        "      show_AI = input()\n",
        "      if show_AI.upper() == \"Y\": # Using .upper()\n",
        "          #Pass images and predictions to function\n",
        "          show_images_predicted_as_AI(test_predictions, image_paths,processed_upload_data)\n",
        "  else:\n",
        "      print(\"Could not create data batches for prediction.\")\n",
        "\n",
        "  #Option: Test more images\n",
        "  run_test = input(\"Would you like to test another image? Y/N\\n\")\n",
        "\n",
        "print(\"\\nThank you for using the Volshebniki, Inc. AI-Generated Art Detector\")\n",
        "\n",
        "#exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OcKZbkZr6F3N",
        "outputId": "0daf08f9-e4ba-42e3-c3d3-71541a26a647"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Volshebniki, Inc. AI-Generated Art Detector\n",
            "\n",
            "\n",
            "\n",
            "Would you like to test an image? Y/N\n",
            "y\n",
            "Would you like to test one image or many?\n",
            "1. One image\n",
            "2. Many images (as a zip file)\n",
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b84a175d-a08e-4150-9568-bab8e04caf94\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b84a175d-a08e-4150-9568-bab8e04caf94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dragon.jpg to dragon (3).jpg\n",
            "User uploaded file \"dragon (3).jpg\" to /contents\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759ms/step\n",
            "Would you like to save the predictions? Y/N\n",
            "\n",
            "y\n",
            "Predictions saved to /content/drive/MyDrive/AI_Art_Detector/predictions/test_predictions_20250713_215651.csv\n",
            "Would you like to see the predictions? Y/N\n",
            "\n",
            "y\n",
            "       Image Name Prediction  Confidence\n",
            "0  dragon (3).jpg         AI  [88.79584]\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Would you like to see images predicted to be AI-generated? Y/N\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R5WGCt2nXcKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}